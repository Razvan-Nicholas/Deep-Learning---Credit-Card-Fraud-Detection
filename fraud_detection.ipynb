{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Credit Card Fraud Detection – Experimental Notebook\n",
        "\n",
        "This notebook contains the complete, reproducible experimental pipeline for the Credit Card Fraud Detection project. It is designed to be executed top-to-bottom without modification.\n",
        "\n",
        "1. Imports and Global Configuration"
      ],
      "metadata": {
        "id": "-rJX-5_0l5IS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "classification_report,\n",
        "confusion_matrix,\n",
        "roc_auc_score,\n",
        "roc_curve,\n",
        "precision_recall_curve\n",
        ")\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)"
      ],
      "metadata": {
        "id": "Qb3ECN36mE8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Dataset Loading and Exploration"
      ],
      "metadata": {
        "id": "hRc9qtKymGJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('../data/creditcard.csv')\n",
        "print(df.shape)\n",
        "df.head()\n",
        "\n",
        "# Class distribution\n",
        "class_counts = df['Class'].value_counts()\n",
        "print(class_counts)\n",
        "print('\\nFraud percentage:', class_counts[1] / len(df) * 100)\n",
        "\n",
        "sns.countplot(x='Class', data=df)\n",
        "plt.title('Class Distribution (0 = Legitimate, 1 = Fraud)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j_UBDJxImIIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: The dataset is extremely imbalanced, which motivates the use of specialized evaluation metrics and resampling techniques."
      ],
      "metadata": {
        "id": "1qlT0S9emb3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Train–Test Split and Feature Scaling"
      ],
      "metadata": {
        "id": "VpdkDr99me3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "X, y,\n",
        "test_size=0.2,\n",
        "stratify=y,\n",
        "random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "1Dt3l7cxmh4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Baseline Models (No Resampling)\n",
        "4.1 Logistic Regression"
      ],
      "metadata": {
        "id": "e7NgGillmj7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(\n",
        "class_weight='balanced',\n",
        "solver='liblinear',\n",
        "random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = lr.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "print('ROC-AUC:', roc_auc_score(y_test, y_pred_lr))"
      ],
      "metadata": {
        "id": "plCSUk5VmnTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2 Random Forest"
      ],
      "metadata": {
        "id": "AzAPcoiZmqS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(\n",
        "n_estimators=200,\n",
        "max_depth=10,\n",
        "class_weight='balanced',\n",
        "random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print('ROC-AUC:', roc_auc_score(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "3LhOSXN7mqrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Handling Class Imbalance with SMOTE"
      ],
      "metadata": {
        "id": "Q-TOM0Q0muLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=RANDOM_STATE)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "print('Before SMOTE:', np.bincount(y_train))\n",
        "print('After SMOTE:', np.bincount(y_train_smote))"
      ],
      "metadata": {
        "id": "ieCQCftxmuvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Deep Learning Model (MLP)\n",
        "6.1 Model Definition"
      ],
      "metadata": {
        "id": "NdyMQ0_vm4Zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_mlp(input_dim, layers=[32, 16], lr=0.001):\n",
        "model = Sequential()\n",
        "for i, units in enumerate(layers):\n",
        "if i == 0:\n",
        "model.add(Dense(units, activation='relu', input_dim=input_dim))\n",
        "else:\n",
        "model.add(Dense(units, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(\n",
        "optimizer=Adam(learning_rate=lr),\n",
        "loss='binary_crossentropy',\n",
        "metrics=['Precision', 'Recall']\n",
        ")\n",
        "return model"
      ],
      "metadata": {
        "id": "7YC6Pbfcm6l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.2 Training the MLP (SMOTE Data)"
      ],
      "metadata": {
        "id": "mz0Ombffm9QP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = build_mlp(input_dim=X_train_smote.shape[1], layers=[32, 16])\n",
        "\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "monitor='val_loss',\n",
        "patience=5,\n",
        "restore_best_weights=True\n",
        ")\n",
        "\n",
        "\n",
        "history = mlp.fit(\n",
        "X_train_smote, y_train_smote,\n",
        "validation_split=0.2,\n",
        "epochs=50,\n",
        "batch_size=256,\n",
        "callbacks=[early_stop],\n",
        "verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "Hd7AAgQcm-eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. MLP Evaluation"
      ],
      "metadata": {
        "id": "UaKCN_5xnCYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_mlp = (mlp.predict(X_test_scaled) > 0.5).astype(int)\n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred_mlp))\n",
        "print('ROC-AUC:', roc_auc_score(y_test, y_pred_mlp))"
      ],
      "metadata": {
        "id": "q70IIa38nDak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Training Curves"
      ],
      "metadata": {
        "id": "9HEmFIEInGOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('MLP Training Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cv0bDHk_nGyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. ROC Curve Comparison"
      ],
      "metadata": {
        "id": "4QJ5Icv-nJKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc(y_true, y_score, label):\n",
        "fpr, tpr, _ = roc_curve(y_true, y_score)\n",
        "plt.plot(fpr, tpr, label=label)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plot_roc(y_test, lr.predict_proba(X_test_scaled)[:,1], 'Logistic Regression')\n",
        "plot_roc(y_test, rf.predict_proba(X_test_scaled)[:,1], 'Random Forest')\n",
        "plot_roc(y_test, mlp.predict(X_test_scaled).ravel(), 'MLP')\n",
        "\n",
        "\n",
        "plt.plot([0,1], [0,1], linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wKSRH1bWnJu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Precision–Recall Curve (Imbalanced Learning Focus)"
      ],
      "metadata": {
        "id": "ofUoOFBynMQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, _ = precision_recall_curve(\n",
        "y_test, mlp.predict(X_test_scaled).ravel()\n",
        ")\n",
        "\n",
        "\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision–Recall Curve (MLP)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wBrw96fKnOGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Summary\n",
        "\n",
        "Traditional ML models provide strong baselines\n",
        "\n",
        "MLP achieves higher recall when combined with SMOTE\n",
        "\n",
        "Precision–Recall analysis is more informative than accuracy\n",
        "\n",
        "Proper imbalance handling is essential for fraud detection"
      ],
      "metadata": {
        "id": "HSp9K_ubnPNR"
      }
    }
  ]
}